{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FH5Ka7ZDkCei",
        "outputId": "fe15c6fe-8216-41f7-c69f-a067ae88bbd7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.data.path.append('/usr/local/nltk_data')\n",
        "nltk.download('punkt', force=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE3U_PHakFVF",
        "outputId": "bae047d5-d8bc-47de-a728-818fd8cca347"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tAcqcvTsIKFn"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from nltk.collocations import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XDqvrmyQIKFr"
      },
      "outputs": [],
      "source": [
        "text1=[\"I am clever because I am learning\",\n",
        "      \"I want to eat English food\",\n",
        "      \"I want to eat Chinese food\",\n",
        "      \"I want to go for a walk\"\n",
        "     ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "psF7TuJ2IKFs"
      },
      "outputs": [],
      "source": [
        "def calculate_specific_probability(text, w1, w2):\n",
        "    text = \" \".join(text)\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    bigrams = nltk.bigrams(tokens)\n",
        "\n",
        "    unigram_counts = Counter(tokens)\n",
        "    bigram_counts = Counter(bigrams)\n",
        "\n",
        "    bigram = (w1, w2)\n",
        "    if unigram_counts[w1] > 0:\n",
        "        return bigram_counts[bigram] / unigram_counts[w1]\n",
        "    else:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sNs6uXphIKFt"
      },
      "outputs": [],
      "source": [
        "def calculate_all_probabilities(text):\n",
        "    text = \" \".join(text)\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    bigrams = nltk.bigrams(tokens)\n",
        "    unigram_counts = Counter(tokens)\n",
        "    bigram_counts = Counter(bigrams)\n",
        "\n",
        "    probabilities = {}\n",
        "\n",
        "    for bigram in bigram_counts:\n",
        "        w1, w2 = bigram\n",
        "        if unigram_counts[w1] > 0:\n",
        "            prob = bigram_counts[bigram] / unigram_counts[w1]\n",
        "        else:\n",
        "            prob = 0\n",
        "        probabilities[bigram] = prob\n",
        "        print(f\"P('{w2}' | '{w1}') = {prob}\")\n",
        "\n",
        "    return probabilities"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_max_probability(probabilities):\n",
        "    max_bigram = max(probabilities, key=probabilities.get)\n",
        "    max_prob = probabilities[max_bigram]\n",
        "    return max_bigram, max_prob\n"
      ],
      "metadata": {
        "id": "mspWnUGim3Wd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5ui3j2_QIKFt",
        "outputId": "ff40a3da-09c4-4827-ad22-12e9ec25a3ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P('want' | 'I') = 0.6\n"
          ]
        }
      ],
      "source": [
        "w1 = \"I\"\n",
        "w2 = \"want\"\n",
        "prob = calculate_specific_probability(text1, w1, w2)\n",
        "print(f\"P('{w2}' | '{w1}') = {prob}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "n4K6oR-rIKFv",
        "outputId": "ae137625-07fb-4a95-b095-23df4bd0cd36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P('am' | 'I') = 0.4\n",
            "P('clever' | 'am') = 0.5\n",
            "P('because' | 'clever') = 1.0\n",
            "P('I' | 'because') = 1.0\n",
            "P('learning' | 'am') = 0.5\n",
            "P('I' | 'learning') = 1.0\n",
            "P('want' | 'I') = 0.6\n",
            "P('to' | 'want') = 1.0\n",
            "P('eat' | 'to') = 0.6666666666666666\n",
            "P('English' | 'eat') = 0.5\n",
            "P('food' | 'English') = 1.0\n",
            "P('I' | 'food') = 1.0\n",
            "P('Chinese' | 'eat') = 0.5\n",
            "P('food' | 'Chinese') = 1.0\n",
            "P('go' | 'to') = 0.3333333333333333\n",
            "P('for' | 'go') = 1.0\n",
            "P('a' | 'for') = 1.0\n",
            "P('walk' | 'a') = 1.0\n"
          ]
        }
      ],
      "source": [
        "probabilities = calculate_all_probabilities(text1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_bigram, max_prob = find_max_probability(probabilities)\n",
        "print(f\"The highest probability is for the bigram {max_bigram} with probability {max_prob}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnAlF3DGnFfd",
        "outputId": "7aec3a09-e042-425a-85d0-e7b98c4b85d4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The highest probability is for the bigram ('clever', 'because') with probability 1.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}